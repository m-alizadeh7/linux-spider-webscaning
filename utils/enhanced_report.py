"""
Enhanced Report Generator Module
Adds Executive Summary, JSON/CSV exports, and marketing-friendly reports
"""

import os
import json
import csv
from datetime import datetime
from typing import Dict, Any, List, Optional


class EnhancedReportGenerator:
    """
    Enhanced report generator with marketing-friendly output
    
    Features:
    - Executive Summary for managers
    - Overall SEO score breakdown
    - Top issues with priorities
    - Article and Product summaries
    - JSON and CSV export
    """
    
    def __init__(self, output_dir: str = 'reports'):
        """
        Initialize enhanced report generator
        
        Args:
            output_dir: Directory to save reports
        """
        self.output_dir = output_dir
        self._ensure_output_dir()
    
    def _ensure_output_dir(self):
        """Ensure output directory exists"""
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
    
    def generate_executive_report(self, scan_results: Dict[str, Any], url: str, 
                                   domain: str) -> str:
        """
        Generate executive summary report
        
        Args:
            scan_results: Complete scan results
            url: Target URL
            domain: Domain name
            
        Returns:
            Path to generated report
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"executive_report_{domain}_{timestamp}.md"
        filepath = os.path.join(self.output_dir, filename)
        
        print(f"\n[*] Generating executive report: {filename}")
        
        with open(filepath, 'w', encoding='utf-8') as f:
            # Header
            f.write(self._generate_exec_header(url, domain, timestamp))
            
            # Executive Summary
            f.write(self._generate_executive_summary(scan_results))
            
            # Score Breakdown
            f.write(self._generate_score_breakdown(scan_results))
            
            # Top Issues
            f.write(self._generate_top_issues(scan_results))
            
            # Articles Summary
            if 'articles' in scan_results:
                f.write(self._generate_articles_summary(scan_results['articles']))
            
            # Products Summary
            if 'products' in scan_results:
                f.write(self._generate_products_summary(scan_results['products']))
            
            # Quick Wins
            f.write(self._generate_quick_wins(scan_results))
            
            # Footer
            f.write(self._generate_exec_footer())
        
        print(f"[+] Executive report saved: {filepath}")
        return filepath
    
    def _generate_exec_header(self, url: str, domain: str, timestamp: str) -> str:
        """Generate executive report header"""
        date_formatted = datetime.strptime(timestamp, '%Y%m%d_%H%M%S').strftime('%Y-%m-%d %H:%M')
        
        return f"""# ğŸ“Š SEO & Content Analysis Report

## Executive Summary

| | |
|---|---|
| **Website** | {url} |
| **Domain** | {domain} |
| **Report Date** | {date_formatted} |
| **Generated By** | Linux Spider Web Scanner |

---

"""
    
    def _generate_executive_summary(self, results: Dict[str, Any]) -> str:
        """Generate executive summary section"""
        # Calculate overall score
        scores = self._calculate_all_scores(results)
        overall_score = scores['overall']
        
        # Determine status
        if overall_score >= 80:
            status = "ğŸŸ¢ Excellent"
            status_desc = "Your website is performing well across all metrics."
        elif overall_score >= 60:
            status = "ğŸŸ¡ Good"
            status_desc = "Your website has room for improvement in some areas."
        elif overall_score >= 40:
            status = "ğŸŸ  Fair"
            status_desc = "Several important issues need attention."
        else:
            status = "ğŸ”´ Needs Work"
            status_desc = "Critical issues are affecting your website's performance."
        
        section = f"""## Overall Score: {overall_score}/100 {status}

{status_desc}

"""
        return section
    
    def _generate_score_breakdown(self, results: Dict[str, Any]) -> str:
        """Generate score breakdown section"""
        scores = self._calculate_all_scores(results)
        
        section = """## Score Breakdown

| Category | Score | Status |
|----------|-------|--------|
"""
        
        categories = [
            ('Technical SEO', scores.get('technical', 0)),
            ('On-Page SEO', scores.get('onpage', 0)),
            ('Content Quality', scores.get('content', 0)),
            ('Structured Data', scores.get('schema', 0)),
            ('Indexability', scores.get('indexability', 0)),
        ]
        
        for name, score in categories:
            if score >= 80:
                status = "ğŸŸ¢ Excellent"
            elif score >= 60:
                status = "ğŸŸ¡ Good"
            elif score >= 40:
                status = "ğŸŸ  Fair"
            else:
                status = "ğŸ”´ Poor"
            
            section += f"| {name} | {score}/100 | {status} |\n"
        
        section += "\n---\n\n"
        return section
    
    def _generate_top_issues(self, results: Dict[str, Any]) -> str:
        """Generate top 10 issues with priorities"""
        issues = self._collect_all_issues(results)
        
        # Sort by priority
        priority_order = {'HIGH': 0, 'MEDIUM': 1, 'LOW': 2}
        issues.sort(key=lambda x: priority_order.get(x.get('priority', 'LOW'), 2))
        
        section = """## ğŸ¯ Top Issues to Fix

"""
        
        if not issues:
            section += "âœ… No critical issues found!\n\n"
            return section + "---\n\n"
        
        # Take top 10
        for i, issue in enumerate(issues[:10], 1):
            priority = issue.get('priority', 'LOW')
            if priority == 'HIGH':
                badge = "ğŸ”´ **HIGH**"
            elif priority == 'MEDIUM':
                badge = "ğŸŸ¡ **MEDIUM**"
            else:
                badge = "ğŸŸ¢ **LOW**"
            
            section += f"""### {i}. {issue.get('title', 'Issue')}

- **Priority:** {badge}
- **Impact:** {issue.get('impact', 'Affects visibility and user experience')}
- **How to Fix:** {issue.get('fix', 'Consult technical documentation')}

"""
        
        if len(issues) > 10:
            section += f"*... and {len(issues) - 10} more issues in detailed report*\n\n"
        
        section += "---\n\n"
        return section
    
    def _generate_articles_summary(self, articles_data: Dict[str, Any]) -> str:
        """Generate articles summary section"""
        total = articles_data.get('total_found', 0)
        
        if total == 0:
            return """## ğŸ“ Articles Analysis

No articles detected on this website.

---

"""
        
        indexable = articles_data.get('indexable_count', 0)
        with_schema = articles_data.get('with_schema', 0)
        thin_content = articles_data.get('thin_content_count', 0)
        missing_meta = articles_data.get('missing_meta_count', 0)
        
        indexable_pct = round(indexable / total * 100, 1) if total > 0 else 0
        schema_pct = round(with_schema / total * 100, 1) if total > 0 else 0
        thin_pct = round(thin_content / total * 100, 1) if total > 0 else 0
        
        section = f"""## ğŸ“ Articles Analysis

| Metric | Value | Status |
|--------|-------|--------|
| **Total Articles Found** | {total} | - |
| **Indexable** | {indexable} ({indexable_pct}%) | {'ğŸŸ¢' if indexable_pct >= 90 else 'ğŸŸ¡' if indexable_pct >= 70 else 'ğŸ”´'} |
| **With Schema Markup** | {with_schema} ({schema_pct}%) | {'ğŸŸ¢' if schema_pct >= 80 else 'ğŸŸ¡' if schema_pct >= 50 else 'ğŸ”´'} |
| **Thin Content (<300 words)** | {thin_content} ({thin_pct}%) | {'ğŸŸ¢' if thin_pct <= 10 else 'ğŸŸ¡' if thin_pct <= 30 else 'ğŸ”´'} |
| **Missing Meta Description** | {missing_meta} | {'ğŸŸ¢' if missing_meta == 0 else 'ğŸŸ¡' if missing_meta <= 5 else 'ğŸ”´'} |

"""
        
        # Top issues for articles
        section += "**Top Article Issues:**\n"
        
        if thin_pct > 10:
            section += f"- âš ï¸ {thin_pct}% of articles have thin content\n"
        if schema_pct < 80:
            section += f"- âš ï¸ Only {schema_pct}% have proper Article schema\n"
        if missing_meta > 0:
            section += f"- âš ï¸ {missing_meta} articles missing meta description\n"
        if indexable_pct < 100:
            section += f"- âš ï¸ {100 - indexable_pct}% of articles are not indexable\n"
        
        if thin_pct <= 10 and schema_pct >= 80 and missing_meta == 0 and indexable_pct >= 95:
            section += "- âœ… Articles are well optimized!\n"
        
        section += "\n---\n\n"
        return section
    
    def _generate_products_summary(self, products_data: Dict[str, Any]) -> str:
        """Generate products summary section"""
        total = products_data.get('total_found', 0)
        
        if total == 0:
            return """## ğŸ›’ Products Analysis

No products detected on this website.

---

"""
        
        with_schema = products_data.get('with_schema', 0)
        with_price = products_data.get('with_price', 0)
        with_availability = products_data.get('with_availability', 0)
        with_rating = products_data.get('with_rating', 0)
        missing_alt = products_data.get('missing_image_alt', 0)
        platform = products_data.get('platform_detected', 'Unknown')
        
        schema_pct = round(with_schema / total * 100, 1) if total > 0 else 0
        price_pct = round(with_price / total * 100, 1) if total > 0 else 0
        avail_pct = round(with_availability / total * 100, 1) if total > 0 else 0
        
        section = f"""## ğŸ›’ Products Analysis

| Metric | Value | Status |
|--------|-------|--------|
| **Total Products Found** | {total} | - |
| **E-commerce Platform** | {platform or 'Not detected'} | - |
| **With Product Schema** | {with_schema} ({schema_pct}%) | {'ğŸŸ¢' if schema_pct >= 80 else 'ğŸŸ¡' if schema_pct >= 50 else 'ğŸ”´'} |
| **With Price in Schema** | {with_price} ({price_pct}%) | {'ğŸŸ¢' if price_pct >= 90 else 'ğŸŸ¡' if price_pct >= 70 else 'ğŸ”´'} |
| **With Availability** | {with_availability} ({avail_pct}%) | {'ğŸŸ¢' if avail_pct >= 90 else 'ğŸŸ¡' if avail_pct >= 70 else 'ğŸ”´'} |
| **With Ratings/Reviews** | {with_rating} | - |
| **Missing Image Alt** | {missing_alt} | {'ğŸŸ¢' if missing_alt == 0 else 'ğŸŸ¡' if missing_alt <= 5 else 'ğŸ”´'} |

"""
        
        # Top issues for products
        section += "**Top Product Issues:**\n"
        
        if schema_pct < 80:
            section += f"- âš ï¸ Only {schema_pct}% have Product schema (affects rich snippets)\n"
        if price_pct < 90:
            section += f"- âš ï¸ {100 - price_pct}% missing price in schema\n"
        if avail_pct < 90:
            section += f"- âš ï¸ {100 - avail_pct}% missing availability in schema\n"
        if missing_alt > 0:
            section += f"- âš ï¸ {missing_alt} products with missing image alt text\n"
        
        if schema_pct >= 80 and price_pct >= 90 and avail_pct >= 90 and missing_alt == 0:
            section += "- âœ… Products are well optimized!\n"
        
        section += "\n---\n\n"
        return section
    
    def _generate_quick_wins(self, results: Dict[str, Any]) -> str:
        """Generate quick wins section"""
        quick_wins = []
        
        # Check for quick win opportunities
        seo = results.get('seo', {})
        technical = results.get('technical_seo', {})
        schema = results.get('schema_validation', {})
        
        # Missing robots.txt
        if technical.get('robots_txt_exists') == False:
            quick_wins.append({
                'action': 'Create robots.txt file',
                'impact': 'Improves crawlability',
                'effort': 'Low (5 minutes)'
            })
        
        # Missing sitemap
        if technical.get('sitemap_exists') == False:
            quick_wins.append({
                'action': 'Create XML sitemap',
                'impact': 'Helps search engines discover pages',
                'effort': 'Low (auto-generate with plugins)'
            })
        
        # Missing viewport
        if technical.get('mobile_viewport') == False:
            quick_wins.append({
                'action': 'Add viewport meta tag',
                'impact': 'Mobile-friendliness',
                'effort': 'Low (1 line of code)'
            })
        
        # Missing schema
        if not schema.get('organization_present', True):
            quick_wins.append({
                'action': 'Add Organization schema',
                'impact': 'Knowledge panel eligibility',
                'effort': 'Medium (JSON-LD block)'
            })
        
        if not schema.get('breadcrumb_present', True):
            quick_wins.append({
                'action': 'Add BreadcrumbList schema',
                'impact': 'Better SERP appearance',
                'effort': 'Medium (JSON-LD block)'
            })
        
        section = """## âš¡ Quick Wins

These are high-impact, low-effort improvements:

"""
        
        if not quick_wins:
            section += "âœ… No quick wins identified - you've covered the basics!\n\n"
            return section + "---\n\n"
        
        section += "| Action | Impact | Effort |\n|--------|--------|--------|\n"
        
        for win in quick_wins[:5]:
            section += f"| {win['action']} | {win['impact']} | {win['effort']} |\n"
        
        section += "\n---\n\n"
        return section
    
    def _generate_exec_footer(self) -> str:
        """Generate executive report footer"""
        return """## Next Steps

1. **Prioritize** the HIGH priority issues
2. **Implement** quick wins first for immediate impact
3. **Monitor** progress with regular scans
4. **Consult** with SEO specialists for complex issues

---

*This report was generated by Linux Spider Web Scanner. For detailed technical analysis, see the full scan report.*
"""
    
    def _calculate_all_scores(self, results: Dict[str, Any]) -> Dict[str, float]:
        """Calculate all score categories"""
        scores = {}
        
        # Technical SEO score
        technical = results.get('technical_seo', {})
        scores['technical'] = technical.get('score', 
            results.get('seo', {}).get('seo_score', 50))
        
        # On-page SEO score
        onpage = results.get('onpage_seo', {})
        scores['onpage'] = onpage.get('score', 
            results.get('seo', {}).get('seo_score', 50))
        
        # Content score
        articles = results.get('articles', {})
        if articles.get('total_found', 0) > 0:
            thin_pct = articles.get('thin_content_count', 0) / articles['total_found'] * 100
            scores['content'] = max(0, 100 - thin_pct * 2)
        else:
            scores['content'] = 50
        
        # Schema score
        schema = results.get('schema_validation', {})
        scores['schema'] = schema.get('coverage_score', 50)
        
        # Indexability score
        articles_indexable = articles.get('indexable_count', 0) / max(1, articles.get('total_found', 1)) * 100
        products = results.get('products', {})
        products_indexable = products.get('indexable_count', 0) / max(1, products.get('total_found', 1)) * 100
        scores['indexability'] = (articles_indexable + products_indexable) / 2 if products.get('total_found', 0) > 0 else articles_indexable
        
        # Overall score
        weights = {
            'technical': 0.25,
            'onpage': 0.25,
            'content': 0.20,
            'schema': 0.15,
            'indexability': 0.15
        }
        
        scores['overall'] = round(sum(scores.get(k, 50) * v for k, v in weights.items()))
        
        return scores
    
    def _collect_all_issues(self, results: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Collect all issues from results"""
        issues = []
        
        # Technical SEO issues
        technical = results.get('technical_seo', {})
        for issue in technical.get('issues', []):
            issues.append({
                'title': issue.get('issue', 'Technical Issue'),
                'priority': issue.get('impact', 'MEDIUM'),
                'impact': 'Affects crawling and indexing',
                'fix': issue.get('fix', '')
            })
        
        # On-page issues
        onpage = results.get('onpage_seo', {})
        for issue in onpage.get('issues', []):
            issues.append({
                'title': issue.get('issue', 'On-page Issue'),
                'priority': issue.get('impact', 'MEDIUM'),
                'impact': 'Affects search visibility',
                'fix': issue.get('fix', '')
            })
        
        # Schema issues
        schema = results.get('schema_validation', {})
        for error in schema.get('errors', []):
            if isinstance(error, dict):
                issues.append({
                    'title': f"Schema: {error.get('message', 'Error')}",
                    'priority': 'HIGH',
                    'impact': 'May lose rich snippet eligibility',
                    'fix': error.get('suggestion', '')
                })
        
        return issues
    
    def export_json(self, scan_results: Dict[str, Any], domain: str) -> str:
        """
        Export scan results to JSON
        
        Args:
            scan_results: Complete scan results
            domain: Domain name
            
        Returns:
            Path to JSON file
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"scan_data_{domain}_{timestamp}.json"
        filepath = os.path.join(self.output_dir, filename)
        
        # Clean results for JSON serialization
        cleaned = self._clean_for_json(scan_results)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(cleaned, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"[+] JSON export saved: {filepath}")
        return filepath
    
    def export_csv(self, data: List[Dict[str, Any]], domain: str, 
                   data_type: str = 'articles') -> str:
        """
        Export articles or products to CSV
        
        Args:
            data: List of article or product data
            domain: Domain name
            data_type: 'articles' or 'products'
            
        Returns:
            Path to CSV file
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{data_type}_{domain}_{timestamp}.csv"
        filepath = os.path.join(self.output_dir, filename)
        
        if not data:
            print(f"[-] No {data_type} to export")
            return ""
        
        # Get all keys from first item
        if isinstance(data[0], dict):
            fieldnames = list(data[0].keys())
        else:
            # Assume it has to_dict method
            fieldnames = list(data[0].to_dict().keys())
        
        with open(filepath, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for item in data:
                if isinstance(item, dict):
                    row = item
                else:
                    row = item.to_dict()
                
                # Flatten lists for CSV
                for key, value in row.items():
                    if isinstance(value, list):
                        row[key] = '; '.join(str(v) for v in value)
                
                writer.writerow(row)
        
        print(f"[+] CSV export saved: {filepath}")
        return filepath
    
    def _clean_for_json(self, obj: Any) -> Any:
        """Clean object for JSON serialization"""
        if isinstance(obj, dict):
            return {k: self._clean_for_json(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._clean_for_json(item) for item in obj]
        elif hasattr(obj, 'to_dict'):
            return obj.to_dict()
        elif hasattr(obj, '__dict__'):
            return self._clean_for_json(obj.__dict__)
        else:
            return obj
